\section{Evaluation}

We evailate \system{}'s ability to avoid a given country, its performance,
and its storage and measurement costs.

\subsection{Country Avoidance}

We measured \system{}'s effectiveness in achieving country avoidance.  We did so by first 
calculating the number of {\it default} paths that avoid a given country.  Then 
we added a single relay, and calculated how many domains the client could 
access without traversing through the given country.  We repeated this approach for 
the remaining two relays.  We conducted the evaluation under the condition that 
the client wished to avoid different countries when accessing the Netherlands top 
100 domains; Figure \ref{fig:avoidance_eval} shows these results.  Each 
line represents the fraction of domains accessible while avoiding the country that 
the line represents.  For example, 46\% of domains are accessible without traversing 
the United States when \system{} is not being used (zero relays), and if \system{} is 
used, then 63\% of domains are accessible without traversing the United States.

\begin{figure}[t!]
\tiny
\centering
\includegraphics[width=.5\textwidth,height=6cm]{avoidance_n_relays}
\caption{The effect of the number of relays on avoidance, for a client
  in the Netherlands. We tested \system{} with up to nine relays.}
\label{fig:avoidance_eval}
\end{figure}

It is evident that \system{} helps a client avoid a foreign country, as the 
fraction of domains accessible without traversing 
the specified country without \system{} is lower than with \system{}.  Additionally, 
adding the first relay provides the greatest increase in 
avoidance, while subsequent relays offer diminishing returns.
Figure \ref{fig:avoidance_eval} also clearly shows how much more difficult (or 
impossible) it is to avoid the United States than any other 
country.  Only 63\% of domains can be accessed while avoiding the United States, 
whereas almost all domains can be accessed while avoiding any other given 
country.  
%This confirms the results presented in Section \ref{avoid_results}, and 
%emphasizes how crucial the systematization of the measurements is for enabling 
%\system{}.

\subsection{Performance}
To measure the performance of \system{}, we measure both 
the throughput and latency.

To measure throughput, we ran {\tt wget} for each 
of the top 100 domains from the client machine in the Netherlands 
using an oracle-generated PAC file.  Because different relays could have been 
used to avoid a single domain, the oracle selected a random relay from those 
that would allow the client to avoid the country.  The oracle generated 
ten PAC files for a client in the Netherlands who wishes to avoid the United States,
 randomly selecting a relay for domains that could have used 
different relays, and {\tt wget} was used for the top 100 domains for each 
PAC file generated.  Based on the {\tt wget} output, we calculate the number 
of seconds to access content using our system and take the average across the 
ten experiments. 

\begin{figure}[t]
\centering
\includegraphics[width=.5\textwidth]{throughput}
\caption{The ratio of RAN throughput to direct throughput.  
The points on the graph are taken from the RON study and represent a ``normal'' overlay network's 
performance.} 
\label{fig:throughput}
\end{figure}

Figure \ref{fig:throughput} shows a CDF of the ratio of \system{}
throughput to direct throughput.  The throughput of
\system{} is not significantly worse than that of default paths.  
In some cases the performance of \system{} is {\it better} than
that of default paths.  Such improvements could be a result of the
relays keeping local traffic local, or due to a closer content replica
being selected.  These results show that \system{}'s performance is
comparable to the performance of accessing domains without \system{}.
Figure \ref{fig:throughput} also compares \system{}'s throughput to
RON's throughput, illustrated with the red dots.  \system{} performs
worse than RON ($x < 1$), which is expected, as the detours that
\system{} introduces inherently inflates paths.  Interestingly, both
RON and \system{} improve throughput for a similar fraction of samples
($x>1$).

To measure the latency of \system{}, we ran {\tt curl} to each of the 
top 100 domains from the client in the Netherlands, while using the ten
oracle-generated PAC files. This provided the time to first byte (TTFB); we 
found the average TTFB when accessing content using \system{} and 
found the TTFB when using direct paths; the results are shown in Figure \ref{fig:latency}.  
The median TTFB for direct paths is 68.5~ms; for \system{} paths the
median is 100.8~ms; 90th percentile TTFB is 22.5~ms and 40.4~ms, respectively.  


\begin{figure}[t]
\centering
\includegraphics[width=.5\textwidth]{latency}
\caption{CDF of Time to First Byte for both \system{} and for direct paths.}
\label{fig:latency}
\end{figure}


\subsection{Storage}
As the number of clients increase, and subsequently the number of paths being 
computed increases, the amount of storage must remain reasonable.  The storage 
used by paths can be calculated:

\[Storage(D,R,C) = (D x R) + 2(C x R) + (C x D) \]

D is the number of domains; R is the number of relays; C is representative of the number of 
clients.  While C {\it represents} clients, it is not the number of {\it actual} clients using the 
system --- it is the number of vantage points the system uses to measure paths 
from client locations.  For the prototype with a single client, the storage space for all 
paths computed is 480KB.  As there is a single PAC file for all clients in 
a country, C will grow much slower than if there was a different PAC file for 
each individual client.  There are 196 countries in the world today, and if 
paths and a PAC file were generated for each country, with 100 domains, and 
three relays, the storage would only be 94MB.  This provides plenty of storage 
for increasing the number of domains included in the PAC file or increasing 
the number of relays in the system.

\subsection{Costs}
In addition to storage, the cost of the measurements used in the system must 
be taken into account.  RIPE Atlas credits are a limited resource, and therefore 
we must earn more credits than we are spending on measurements.  The cost 
in credits follows the equation:

\[Credit\_Cost(D,R,C) = COST_{traceroute}((C x R) + (C x D))\]

Currently, the $COST_{traceroute}$ is 60, resulting in a prototype cost of 6,180 
credits, but because these paths are updated each hour, then 
the daily credit cost is 148,320 credits.  In return for hosting a RIPE Atlas 
probe, we earn 216,000 credits per day, which will support our existing 
prototype.  In order to provide for more clients, more domains, or more 
resources, we can tune the system to re-compute paths less frequently (only when necessary).
